---
title: 'Keras Examples'
output:
    rmdformats::readthedown:
      highlight: pygments
      code_folding: show
---
<style type="text/css">
p{ /* Normal  */
   font-size: 14px;
   line-height: 18px;
}
body{ /* Normal  */
   font-size: 14px;
}
td {  /* Table  */
   font-size: 12px;
}
h1 { /* Header 1 */
font-size: 26px;
color: #4294ce;
}
h2 { /* Header 2 */
font-size: 22px;
}
h3 { /* Header 3 */
font-size: 18px;
}
code.r{ /* Code block */
  font-size: 12px;
}
pre { /* Code block */
  font-size: 12px
}
#table-of-contents h2 {
background-color: #4294ce;
}
#table-of-contents{
background: #688FAD;
}
#nav-top span.glyphicon{
color: #4294ce;
}
#postamble{
background: #4294ce;
border-top: ;
}
</style>


```{r loadLibs1, warning=FALSE, message=FALSE}
#if(!require(bayesian_first_aid)){devtools::install_github("rasmusab/bayesian_first_aid")}
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("plyr","dplyr","ggplot2", "readr", "tidyr", "kerasR", prompt = FALSE)

options(scipen = 999)#Do not display exponents

#load("~/GitHub/LargeDataFiles/TreeAlgoCompare.RData")
```

# Introduction

> kerasR is not as well maintained as RStudio's keras package.  This was rewritten to use keras, not kerasR

. In this vignette we illustrate the basic usage of the R interface to Keras. A self-contained introduction to general neural networks is outside the scope of this document; if you are unfamiliar with the general principles we suggest consulting one of the excellent external tutorials. Suggestions include:

- [Hacker’s guide to Neural Networks](http://karpathy.github.io/neuralnets/)
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [A Beginner’s Guide to Recurrent Networks and LSTMs](https://deeplearning4j.org/lstm)

Specific research papers for many advanced layers are also included in the R documentation.

# Small Example with Boston Housing Data

Building a model in Keras starts by constructing an empty Sequential model.

```{r}
library(keras)
mod <- keras_model_sequential()
```

The result of Sequential, as with most of the functions provided by `kerasR`, is a `python.builtin.object`. This object type, defined from the `reticulate` package, provides direct access to all of the methods and attributes exposed by the underlying python class. To access these, we use the $ operator followed by the method name. Layers are added by calling the method `add`. This function takes as an input another `python.builtin.object`, generally constructed as the output of another `kerasR` function. For example, to add a dense layer to our model we do the following:

```{r eval = FALSE}
mod$add(layer_dense(units = 50, input_shape = 13))
```

We have now added a dense layer with 200 neurons. The first layer must include a specification of the input_shape, giving the dimensionality of the input data. Here we set the number of input variables equal to 13. Next in the model, we add an activation defined by a rectified linear unit to the model:

```{r eval=FALSE}
mod$add(layer_activation_relu())
```

Now add a dense layer with just a single neuron to serve as the output layer:

```{r eval=`}
mod$add(layer_dense(units = 1))
```

Once the model is fully defined, we have to compile it before fitting its parameters or using it for prediction. Compiling a model can be done with the method compile, but some optional arguments to it can cause trouble when converting from R types so we provide a custom wrapper keras_compile. At a minimum we need to specify the loss function and the optimizer. The loss can be specified with just a string, but we will pass the output of another kerasR function as the optimizer. Here we use the RMSprop optimizer as it generally gives fairly good performance:

```{r}
mod %>% compile(loss = 'mse', optimizer = optimizer_rmsprop(), metrics = "acc")
```

Now we are able to fit the weights in the model from some training data, but we do not yet have any data from which to train! Let’s load some using the wrapper function load_boston_housing. We provide several data loading functions as part of the package, and all return data in the same format. In this case it will be helpful to scale the data matrices:

```{r}
boston <- kerasR::load_boston_housing()
X_train <- scale(boston$X_train)
Y_train <- boston$Y_train
X_test <- scale(boston$X_test)
Y_test <- boston$Y_test
```

Now, we call the wrapper keras_fit in order to fit the model from this data. As with the compilation, there is a direct method for doing this but you will likely run into data type conversion problems calling it directly. Instead, we see how easy it is to use the wrapper function (if you run this yourself, you will see that Keras provides very good verbose output for tracking the fitting of models):

```{r}
history <- mod %>% fit(X_train, Y_train, batch_size = 32, epochs = 80, verbose = 1, validation_split = 0.1)
plot(history)
```
